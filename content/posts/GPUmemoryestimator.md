+++
title = 'GPUmemoryestimator'
date = 2025-01-12T19:21:08+08:00
draft = false 
+++

# GPU memory estimator for LLM
This is a tool designed to help you estimate GPU memory requirements for large language models (LLMs) based on the number of parameters and precision settings. It can be accessed via the following link:

[Visit GPU Memory Estimator](https://gpumemoryestimator.williamswang.win)

By providing the parameter count and precision, you can quickly get an estimate of the GPU VRAM required to run the model efficiently.

